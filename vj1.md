# ğŸ› ï¸ Automatski ETL proces u Pythonu
**Modularna struktura za studente (sa MSSQL bazom)**

## ğŸ“Œ Uvod
ETL proces (Extract â€“ Transform â€“ Load) je osnovni korak u radu s podacima. 
Ovdje prikazujemo kako napraviti automatizovan, modularan ETL sistem koristeÄ‡i Python i MSSQL bazu podataka.

---

## ğŸ“ Struktura projekta

```
etl_project/
â”œâ”€â”€ data/                          # Ulazni CSV fajl
â”œâ”€â”€ main.py                        # Ulazna taÄka koja pokreÄ‡e ETL proces
â”œâ”€â”€ requirements.txt               # Biblioteke potrebne za rad
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ extract/
    â”‚   â””â”€â”€ extractor.py           # UÄitavanje podataka
    â”œâ”€â”€ transform/
    â”‚   â””â”€â”€ transformer.py         # ÄŒiÅ¡Ä‡enje i obrada podataka
    â””â”€â”€ load/
        â””â”€â”€ loader.py              # Ubacivanje u MSSQL bazu
```

---

## ğŸ§© Korak 1: EXTRACT â€“ UÄitavanje podataka

```python
import pandas as pd

def load_dataset(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    print(f"Loaded {len(df)} rows and {len(df.columns)} columns.")
    return df
```

> Dataset treba biti smjeÅ¡ten u folder `data/`, npr. `students_performance.csv`.

---

## ğŸ§ª Korak 2: TRANSFORM â€“ ÄŒiÅ¡Ä‡enje i priprema podataka

```python
def clean_dataset(df):
    df = df.drop_duplicates()
    df = df.fillna(0)
    return df
```

MoguÄ‡e dodatne transformacije:
- Encoding kategorijalnih vrijednosti
- Formatiranje datuma
- Skaliranje numeriÄkih vrijednosti

---

## ğŸ—„ï¸ Korak 3: LOAD â€“ Slanje u MSSQL bazu

```python
from sqlalchemy import create_engine

def load_to_mssql(df, table_name, connection_string):
    engine = create_engine(connection_string)
    df.to_sql(table_name, con=engine, if_exists='replace', index=False)
    print(f"Data loaded to table: {table_name}")
```

ğŸ” Primjer konekcijskog stringa:

```
mssql+pyodbc://USERNAME:PASSWORD@HOSTNAME/DATABASENAME?driver=ODBC+Driver+17+for+SQL+Server
```

---

## â–¶ï¸ main.py

```python
from src.extract.extractor import load_dataset
from src.transform.transformer import clean_dataset
from src.load.loader import load_to_mssql

dataset_path = "data/students_performance.csv"
table_name = "students"
connection_string = "mssql+pyodbc://USERNAME:PASSWORD@HOSTNAME/DBNAME?driver=ODBC+Driver+17+for+SQL+Server"

df = load_dataset(dataset_path)
df_clean = clean_dataset(df)
load_to_mssql(df_clean, table_name, connection_string)
```

---

## ğŸ“¦ requirements.txt

```
pandas
sqlalchemy
pyodbc
```

Instalacija:
```
pip install -r requirements.txt
```

---

## ğŸ“ˆ ZakljuÄak

Ova struktura omoguÄ‡ava:
- Automatizaciju ETL procesa
- Modularnost koda
- Spremnost za nadogradnju i profesionalnu upotrebu

---

## ğŸ§ª Primjer za testiranje

Dataset: [Students Performance in Exams](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams)  
Fajl: `students_performance.csv` staviti u `data/` folder.

Pokretanje:
```
python main.py
```
